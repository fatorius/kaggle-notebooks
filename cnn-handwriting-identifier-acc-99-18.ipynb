{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import os \nimport keras\nimport numpy as np\nimport tensorflow as tf\n\nimport pandas as pd\nfrom keras.preprocessing.image import ImageDataGenerator \nfrom sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.regularizers import l2\n\nfrom keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Activation, BatchNormalization\n\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Abrindo o dataset","metadata":{}},{"cell_type":"code","source":"\nfile_path = '/kaggle/input/az-handwritten-alphabets-in-csv-format/A_Z Handwritten Data.csv'\n\nnames = ['class']\nfor id in range(1,785):\n    names.append(id)\n\ndf = pd.read_csv(file_path,header=None, names=names)\n\nclass_mapping = {}\nalphabets = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\nfor i in range(len(alphabets)):\n    class_mapping[i] = alphabets[i]\n    \ndf['class'].map(class_mapping).unique()\n\ny_full = df.pop('class')\nx_full = df.to_numpy().reshape(-1,28,28, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_split = 0.2\n\nsplitter = StratifiedShuffleSplit(n_splits=3,test_size=val_split)\n\nfor train_ids, test_ids in splitter.split(x_full, y_full):\n    X_train_full, y_train_full = x_full[train_ids], y_full[train_ids].to_numpy()\n    X_test, y_test = x_full[test_ids], y_full[test_ids].to_numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=val_split)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre-processando as imagens\n\nPara facilitar o aprendizado do modelo, as imagens serão pre-processadas.","metadata":{}},{"cell_type":"markdown","source":"## Imagens antes do pre-processamento","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,8))\nfor i in range(1, 11):\n    \n    id = np.random.randint(len(X_train))\n    image, label = tf.squeeze(X_train[id]), class_mapping[int(y_train[id])]\n    \n    plt.subplot(2,5,i)\n    plt.imshow(image, cmap='binary')\n    plt.title(label)\n    plt.axis('off')\n    \nplt.tight_layout()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = (X_train > 125)\nX_test = (X_test > 125) \nX_valid = (X_valid > 125) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Imagens após o pré-processamento","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,8))\nfor i in range(1, 11):\n    \n    id = np.random.randint(len(X_train))\n    image, label = tf.squeeze(X_train[id]), class_mapping[int(y_train[id])]\n    \n    plt.subplot(2,5,i)\n    plt.imshow(image, cmap='binary')\n    plt.title(label)\n    plt.axis('off')\n    \nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Os valores dos pixels em escala de cinza (entre 0 e 255) podem confudir a rede durante seu aprendizado, portanto todas as imagens que constituem o conjunto de dados foram binarizadas, aplicando um threshold para valores maiores que 125.","metadata":{}},{"cell_type":"markdown","source":"# Aumento de dados\n\nPara o treino, também será usado uma técnica de aumento de dados, onde as imagens serão aleatoriamente rotacionadas em 10 graus para ambas as direções, além de ampliadas, movidas e diminuidas em 10%.\n\nAo proporcionar mais dados para treino, essa técnica permite com que o modelo aprenda em cima de dados irregulares e diferentes dos previamente vistos, assim aumentando seu reconhecimento dos padrões dos caracteres. ","metadata":{}},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center = False,\n        samplewise_center = False,\n        featurewise_std_normalization = False,\n        samplewise_std_normalization = False,\n        zca_whitening = False,\n        rotation_range = 10,\n        zoom_range = 0.1, \n        width_shift_range = 0.1,  \n        height_shift_range = 0.1, \n        horizontal_flip = False,  \n        vertical_flip = False,\n        validation_split=val_split\n) \n\ndatagen.fit(X_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Arquitetura do modelo\n\nO modelo de redes neurais é composto por camadas convolucionais. \nEm algumas camadas foi utilizado a Regularização L2 para evitar o overfit.\nOutras tecnicas para evitar o overfit também foram utilizadas, como camadas Dropout e o callback de ReduceLROnPlateau, que reduz a taxa de aprendizado da rede caso esta fique estagnada.\n\nTambém existem camadas de BatchNormalization, responsáveis por normalizar as ativações das camadas anteriores, permitindo com que as camadas aprendam de forma mais indenpendente e não sejam tão influenciadas pelas ativações das camadas anteriores. \n","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n    Conv2D(filters = 32, kernel_size = 5, strides = 1, activation = 'relu', input_shape = (28,28,1), kernel_regularizer=l2(0.0005), name = 'convolution_1'),\n    Conv2D(filters = 32, kernel_size = 5, strides = 1, name = 'convolution_2', use_bias=False),\n    \n    BatchNormalization(name = 'batchnorm_1'),\n        \n    Activation(\"relu\"),\n    MaxPooling2D(pool_size = 2, strides = 2, name = 'max_pool_1'),\n    Dropout(0.25, name = 'dropout_1'),\n        \n    Conv2D(filters = 64, kernel_size = 3, strides = 1, activation = 'relu', kernel_regularizer=l2(0.0005), name = 'convolution_3'),\n        \n    Conv2D(filters = 64, kernel_size = 3, strides = 1, name = 'convolution_4', use_bias=False),\n        \n    BatchNormalization(name = 'batchnorm_2'),\n        \n    Activation(\"relu\"),\n    MaxPooling2D(pool_size = 2, strides = 2, name = 'max_pool_2'),\n    \n    Dropout(0.25, name = 'dropout_2'),\n    Flatten(name = 'flatten'),\n        \n    Dense(units = 256, name = 'fully_connected_1', use_bias=False),\n        \n    BatchNormalization(name = 'batchnorm_3'),\n    \n    Activation(\"relu\"),\n        \n    Dense(units = 128, name = 'fully_connected_2', use_bias=False),\n        \n    BatchNormalization(name = 'batchnorm_4'),\n        \n    Activation(\"relu\"),\n    \n    Dense(units = 84, name = 'fully_connected_3', use_bias=False),\n        \n    BatchNormalization(name = 'batchnorm_5'),\n        \n    Activation(\"relu\"),\n    \n    Dropout(0.25, name = 'dropout_3'),\n    \n    Dense(26, activation='softmax')\n])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n     loss='sparse_categorical_crossentropy',\n     optimizer='adam',\n     metrics=['accuracy']\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cbs = [\n    EarlyStopping(patience=3, restore_best_weights=True), \n    ModelCheckpoint(\"Model-v1.h5\", save_best_only=True),\n    ReduceLROnPlateau(monitor='val_loss', factor = 0.2, patience = 2)\n]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(\n     datagen.flow(X_train, y_train, batch_size=64,subset='training'),\n     validation_data=(X_valid, y_valid),\n     epochs=50,\n     callbacks=cbs\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testes\n\nO conjunto de testes foi composto por 2328 samples","metadata":{}},{"cell_type":"code","source":"model.evaluate(X_test,y_test) #[0.035956788808107376, 0.9918245077133179]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Após o treinamento, a rede teve um desempenho de 99.18% de precisão no conjunto de testes ","metadata":{}}]}